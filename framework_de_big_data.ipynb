{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d6ca84",
   "metadata": {},
   "source": [
    "#### Framework de Big Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd59115f",
   "metadata": {},
   "source": [
    "#### Conteúdo - Bases e Notebook da aula\n",
    "\n",
    "Base disponivel no caminho:  \n",
    "\n",
    "https://github.com/FIAP/Pos_Tech_DTAT/tree/Framework-de-Big-Data\n",
    "\n",
    "E para correto funcionamento foi necessario a criação de um roteiro de instalação e configuração: \n",
    "\n",
    "https://github.com/RicardViana/fiap-Big-Data/blob/main/PySpark%20para%20VS%20Code%20e%20Anaconda.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770d68e",
   "metadata": {},
   "source": [
    "#### Importação de pacotes, bibliotecas e funções (def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "733f8511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar biblioteca completa\n",
    "import pandas as pd \n",
    "import findspark\n",
    "import urllib.request\n",
    "\n",
    "# Importar função especifica de um módulo\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Import spark libraries\n",
    "from pyspark.sql import Row, DataFrame\n",
    "from pyspark.sql.types import StringType, StructType, StructField, IntegerType\n",
    "from pyspark.sql.functions import col, expr, lit, substring, concat, concat_ws, when, coalesce\n",
    "from pyspark.sql import functions as F\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4d2a35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como não queremos configurar as variaveis de ambiente, precisamos usar o findspark.init\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70f28a",
   "metadata": {},
   "source": [
    "#### Aula 1 - Conhecendo o Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "352c0cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.count: 561\n",
      "df.col ct: 6\n",
      "df.columns: ['Bank Name', 'City', 'ST', 'CERT', 'Acquiring Institution', 'Closing Date']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "1. spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "Esta é a linha que inicializa o Spark. Ela é o ponto de entrada para qualquer funcionalidade do Spark.\n",
    "\n",
    "SparkSession: É o principal ponto de entrada para a programação com DataFrames e Datasets no Spark.\n",
    "\n",
    ".builder: É um padrão de projeto (builder pattern) usado para construir o objeto SparkSession com diferentes configurações.\n",
    "\n",
    ".master(\"local[*]\"): Esta é uma das configurações mais importantes. Ela define como e onde o Spark irá executar suas tarefas.\n",
    "\n",
    "\"local[*]\" instrui o Spark a ser executado em modo local, utilizando todos os núcleos de processamento (cores) disponíveis na sua máquina. \n",
    "Se você quisesse usar apenas 2 núcleos, por exemplo, usaria \"local[2]\". Este modo é ideal para desenvolvimento, testes e aprendizado em uma única máquina.\n",
    "\n",
    ".getOrCreate(): Este método cria uma nova SparkSession se uma não existir. Se já houver uma sessão ativa com as mesmas configurações, ele simplesmente a retorna. \n",
    "Isso evita a criação de múltiplas sessões desnecessariamente.\n",
    "\n",
    "Em resumo: esta linha cria e configura uma sessão do Spark para rodar localmente na sua máquina, usando todos os recursos de processamento disponíveis, e armazena essa sessão na variável spark.\n",
    "\n",
    "2. df = spark.read.csv(link, sep= \",\", inferSchema = True, header = True)\n",
    "Esta é a linha que efetivamente lê os dados e os transforma em um DataFrame, que é a principal estrutura de dados do Spark.\n",
    "\n",
    "spark.read: É o objeto usado para ler dados de fontes externas (arquivos, bancos de dados, etc.).\n",
    "\n",
    ".csv(link, ...): Especifica que o formato do arquivo a ser lido é CSV. O primeiro argumento, link, é o caminho para o arquivo.\n",
    "\n",
    "sep= \",\": Este parâmetro (separador) informa ao Spark que as colunas no arquivo CSV são delimitadas por uma vírgula. É o padrão para arquivos CSV, mas é uma boa prática especificá-lo.\n",
    "\n",
    "inferSchema = True: Esta é uma opção muito útil. Ela instrui o Spark a analisar uma amostra dos dados para inferir (deduzir) automaticamente o tipo de dado de cada coluna. \n",
    "Por exemplo, ele tentará identificar se uma coluna contém números inteiros (IntegerType), números decimais (DoubleType) ou texto (StringType). Sem isso, todas as colunas seriam tratadas como texto (String).\n",
    "\n",
    "header = True: Esta opção informa ao Spark que a primeira linha do arquivo CSV contém os nomes das colunas (cabeçalho) e que essa linha não deve ser tratada como dados. \n",
    "O Spark usará esses nomes para as colunas do DataFrame.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "# Baixar o arquivo pois não conseguimos usar o Spark para ler diretamnte o arquivo no Github\n",
    "url = \"https://raw.githubusercontent.com/FIAP/Pos_Tech_DTAT/refs/heads/Framework-de-Big-Data/Aula%201/banklist.csv\"\n",
    "local_path = \"banklist.csv\"\n",
    "urllib.request.urlretrieve(url, local_path)\n",
    "\n",
    "# Ler com Spark\n",
    "df = spark.read.csv(local_path, sep=\",\", header=True, inferSchema=True)\n",
    "\n",
    "print(f\"df.count: {df.count()}\")\n",
    "print(f\"df.col ct: {len(df.columns)}\")\n",
    "print(f\"df.columns: {df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "18b59f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-------------+------------+\n",
      "|Bank Name                       |City         |Closing Date|\n",
      "+--------------------------------+-------------+------------+\n",
      "|The First State Bank            |Barboursville|3-Apr-20    |\n",
      "|Ericson State Bank              |Ericson      |14-Feb-20   |\n",
      "|City National Bank of New Jersey|Newark       |1-Nov-19    |\n",
      "|Resolute Bank                   |Maumee       |25-Oct-19   |\n",
      "+--------------------------------+-------------+------------+\n",
      "only showing top 4 rows\n"
     ]
    }
   ],
   "source": [
    "# Criar uma tabela temporaria\n",
    "df.createOrReplaceTempView(\"banklist\")\n",
    "\n",
    "# Fazer o select \n",
    "df_check = spark.sql(''' select `Bank Name`, `City`,`Closing Date` from banklist ''')\n",
    "df_check.show(4, truncate=False) # --> Retornar apenas os 4 primeiros dados e não truncar textos longos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "aacacb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-------+----+-----------------+---------------------+------------+\n",
      "|summary|           Bank Name|   City|  ST|             CERT|Acquiring Institution|Closing Date|\n",
      "+-------+--------------------+-------+----+-----------------+---------------------+------------+\n",
      "|  count|                 561|    561| 561|              561|                  561|         561|\n",
      "|   mean|                NULL|   NULL|NULL|31685.68449197861|                 NULL|        NULL|\n",
      "| stddev|                NULL|   NULL|NULL|16446.65659309965|                 NULL|        NULL|\n",
      "|    min|1st American Stat...|Acworth|  AL|               91|      1st United Bank|    1-Aug-08|\n",
      "|    max|               ebank|Wyoming|  WY|            58701|  Your Community Bank|    9-Sep-11|\n",
      "+-------+--------------------+-------+----+-----------------+---------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executar a estatistica descritiva \n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c7b537ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+\n",
      "|summary|   City|  ST|\n",
      "+-------+-------+----+\n",
      "|  count|    561| 561|\n",
      "|   mean|   NULL|NULL|\n",
      "| stddev|   NULL|NULL|\n",
      "|    min|Acworth|  AL|\n",
      "|    max|Wyoming|  WY|\n",
      "+-------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executar a estatistica descritiva \n",
    "df.describe('City', 'ST').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a574c3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas: 561\n",
      "Total de colunas: 6\n",
      "Colunas: ['Bank Name', 'City', 'ST', 'CERT', 'Acquiring Institution', 'Closing Date']\n",
      "Tipo de dados: [('Bank Name', 'string'), ('City', 'string'), ('ST', 'string'), ('CERT', 'int'), ('Acquiring Institution', 'string'), ('Closing Date', 'string')]\n",
      "Schema StructType([StructField('Bank Name', StringType(), True), StructField('City', StringType(), True), StructField('ST', StringType(), True), StructField('CERT', IntegerType(), True), StructField('Acquiring Institution', StringType(), True), StructField('Closing Date', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "# Ver informações do data frame \n",
    "print(f\"Total de linhas: {df.count()}\")\n",
    "print(f\"Total de colunas: {len(df.columns)}\")\n",
    "print(f\"Colunas: {df.columns}\")\n",
    "print(f\"Tipo de dados: {df.dtypes}\")\n",
    "print(f\"Schema {df.schema}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5179310e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Bank Name: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- ST: string (nullable = true)\n",
      " |-- CERT: integer (nullable = true)\n",
      " |-- Acquiring Institution: string (nullable = true)\n",
      " |-- Closing Date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ver o Schema dos dados \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb12162a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.count: 561\n",
      "df.columns: ['Bank Name', 'City', 'ST', 'CERT', 'Acquiring Institution', 'Closing Date']\n"
     ]
    }
   ],
   "source": [
    "# Remover duplicadas \n",
    "df = df.dropDuplicates()\n",
    "print(f\"df.count: {df.count()}\")\n",
    "print(f\"df.columns: {df.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9a89c4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+----------------+\n",
      "|Bank Name                        |City            |\n",
      "+---------------------------------+----------------+\n",
      "|First Bank of Idaho              |Ketchum         |\n",
      "|Amcore Bank, National Association|Rockford        |\n",
      "|Venture Bank                     |Lacey           |\n",
      "|First State Bank of Altus        |Altus           |\n",
      "|Valley Capital Bank, N.A.        |Mesa            |\n",
      "|Michigan Heritage Bank           |Farmington Hills|\n",
      "|Columbia Savings Bank            |Cincinnati      |\n",
      "|Fidelity Bank                    |Dearborn        |\n",
      "|The Park Avenue Bank             |Valdosta        |\n",
      "|Western Commercial Bank          |Woodland Hills  |\n",
      "|Syringa Bank                     |Boise           |\n",
      "|Republic Federal Bank, N.A.      |Miami           |\n",
      "|Westside Community Bank          |University Place|\n",
      "|First United Bank                |Crete           |\n",
      "|HarVest Bank of Maryland         |Gaithersburg    |\n",
      "|BankEast                         |Knoxville       |\n",
      "|Polk County Bank                 |Johnston        |\n",
      "|Colorado Capital Bank            |Castle Rock     |\n",
      "|Access Bank                      |Champlin        |\n",
      "|Pacific National Bank            |San Francisco   |\n",
      "+---------------------------------+----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Selecionar colunas especificas do Data Set\n",
    "df2 = df.select(*['Bank Name', 'City'])\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "470d74f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+----------------------------------------------------+------------+----------------+\n",
      "|Bank Name                        |Acquiring Institution                               |Closing Date|City            |\n",
      "+---------------------------------+----------------------------------------------------+------------+----------------+\n",
      "|First Bank of Idaho              |U.S. Bank, N.A.                                     |24-Apr-09   |Ketchum         |\n",
      "|Amcore Bank, National Association|Harris N.A.                                         |23-Apr-10   |Rockford        |\n",
      "|Venture Bank                     |First-Citizens Bank & Trust Company                 |11-Sep-09   |Lacey           |\n",
      "|First State Bank of Altus        |Herring Bank                                        |31-Jul-09   |Altus           |\n",
      "|Valley Capital Bank, N.A.        |Enterprise Bank & Trust                             |11-Dec-09   |Mesa            |\n",
      "|Michigan Heritage Bank           |Level One Bank                                      |24-Apr-09   |Farmington Hills|\n",
      "|Columbia Savings Bank            |United Fidelity Bank, fsb                           |23-May-14   |Cincinnati      |\n",
      "|Fidelity Bank                    |The Huntington National Bank                        |30-Mar-12   |Dearborn        |\n",
      "|The Park Avenue Bank             |Bank of the Ozarks                                  |29-Apr-11   |Valdosta        |\n",
      "|Western Commercial Bank          |First California Bank                               |5-Nov-10    |Woodland Hills  |\n",
      "|Syringa Bank                     |Sunwest Bank                                        |31-Jan-14   |Boise           |\n",
      "|Republic Federal Bank, N.A.      |1st United Bank                                     |11-Dec-09   |Miami           |\n",
      "|Westside Community Bank          |Sunwest Bank                                        |11-Jan-13   |University Place|\n",
      "|First United Bank                |Old Plank Trail Community Bank, National Association|28-Sep-12   |Crete           |\n",
      "|HarVest Bank of Maryland         |Sonabank                                            |27-Apr-12   |Gaithersburg    |\n",
      "|BankEast                         |U.S. Bank, N.A.                                     |27-Jan-12   |Knoxville       |\n",
      "|Polk County Bank                 |Grinnell State Bank                                 |18-Nov-11   |Johnston        |\n",
      "|Colorado Capital Bank            |First-Citizens Bank & Trust Company                 |8-Jul-11    |Castle Rock     |\n",
      "|Access Bank                      |PrinsBank                                           |7-May-10    |Champlin        |\n",
      "|Pacific National Bank            |U.S. Bank N.A.                                      |30-Oct-09   |San Francisco   |\n",
      "+---------------------------------+----------------------------------------------------+------------+----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Selecionar colunas exceto o que tiver na lista \n",
    "col_l = list(set(df.columns) - {'ST', 'CERT'})\n",
    "df2 = df.select(*col_l)\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1bf6bc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----+-----+--------------------+------------+\n",
      "|           bank_name|            City|state| cert|     acq_institution|closing_date|\n",
      "+--------------------+----------------+-----+-----+--------------------+------------+\n",
      "| First Bank of Idaho|         Ketchum|   ID|34396|     U.S. Bank, N.A.|   24-Apr-09|\n",
      "|Amcore Bank, Nati...|        Rockford|   IL| 3735|         Harris N.A.|   23-Apr-10|\n",
      "|        Venture Bank|           Lacey|   WA|22868|First-Citizens Ba...|   11-Sep-09|\n",
      "|First State Bank ...|           Altus|   OK| 9873|        Herring Bank|   31-Jul-09|\n",
      "|Valley Capital Ba...|            Mesa|   AZ|58399|Enterprise Bank &...|   11-Dec-09|\n",
      "|Michigan Heritage...|Farmington Hills|   MI|34369|      Level One Bank|   24-Apr-09|\n",
      "|Columbia Savings ...|      Cincinnati|   OH|32284|United Fidelity B...|   23-May-14|\n",
      "|       Fidelity Bank|        Dearborn|   MI|33883|The Huntington Na...|   30-Mar-12|\n",
      "|The Park Avenue Bank|        Valdosta|   GA|19797|  Bank of the Ozarks|   29-Apr-11|\n",
      "|Western Commercia...|  Woodland Hills|   CA|58087|First California ...|    5-Nov-10|\n",
      "|        Syringa Bank|           Boise|   ID|34296|        Sunwest Bank|   31-Jan-14|\n",
      "|Republic Federal ...|           Miami|   FL|22846|     1st United Bank|   11-Dec-09|\n",
      "|Westside Communit...|University Place|   WA|33997|        Sunwest Bank|   11-Jan-13|\n",
      "|   First United Bank|           Crete|   IL|20685|Old Plank Trail C...|   28-Sep-12|\n",
      "|HarVest Bank of M...|    Gaithersburg|   MD|57766|            Sonabank|   27-Apr-12|\n",
      "|            BankEast|       Knoxville|   TN|19869|     U.S. Bank, N.A.|   27-Jan-12|\n",
      "|    Polk County Bank|        Johnston|   IA|14194| Grinnell State Bank|   18-Nov-11|\n",
      "|Colorado Capital ...|     Castle Rock|   CO|34522|First-Citizens Ba...|    8-Jul-11|\n",
      "|         Access Bank|        Champlin|   MN|16476|           PrinsBank|    7-May-10|\n",
      "|Pacific National ...|   San Francisco|   CA|30006|      U.S. Bank N.A.|   30-Oct-09|\n",
      "+--------------------+----------------+-----+-----+--------------------+------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Renomear as colunas \n",
    "df2 = df \\\n",
    "  .withColumnRenamed('Bank Name'            , 'bank_name') \\\n",
    "  .withColumnRenamed('Acquiring Institution', 'acq_institution') \\\n",
    "  .withColumnRenamed('Closing Date'         , 'closing_date') \\\n",
    "  .withColumnRenamed('ST'                   , 'state') \\\n",
    "  .withColumnRenamed('CERT'                 , 'cert') \n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3aba35bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---+-----+---------------------+------------+-----+\n",
      "|           Bank Name|    City| ST| CERT|Acquiring Institution|Closing Date|State|\n",
      "+--------------------+--------+---+-----+---------------------+------------+-----+\n",
      "| First Bank of Idaho| Ketchum| ID|34396|      U.S. Bank, N.A.|   24-Apr-09|   ID|\n",
      "|Amcore Bank, Nati...|Rockford| IL| 3735|          Harris N.A.|   23-Apr-10|   IL|\n",
      "|        Venture Bank|   Lacey| WA|22868| First-Citizens Ba...|   11-Sep-09|   WA|\n",
      "|First State Bank ...|   Altus| OK| 9873|         Herring Bank|   31-Jul-09|   OK|\n",
      "|Valley Capital Ba...|    Mesa| AZ|58399| Enterprise Bank &...|   11-Dec-09|   AZ|\n",
      "+--------------------+--------+---+-----+---------------------+------------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Adicionar uma nova coluna \n",
    "df2 = df.withColumn('State', col('ST'))\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "57a33a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---+-----+---------------------+------------+-------+\n",
      "|           Bank Name|    City| ST| CERT|Acquiring Institution|Closing Date|country|\n",
      "+--------------------+--------+---+-----+---------------------+------------+-------+\n",
      "| First Bank of Idaho| Ketchum| ID|34396|      U.S. Bank, N.A.|   24-Apr-09|     US|\n",
      "|Amcore Bank, Nati...|Rockford| IL| 3735|          Harris N.A.|   23-Apr-10|     US|\n",
      "|        Venture Bank|   Lacey| WA|22868| First-Citizens Ba...|   11-Sep-09|     US|\n",
      "|First State Bank ...|   Altus| OK| 9873|         Herring Bank|   31-Jul-09|     US|\n",
      "|Valley Capital Ba...|    Mesa| AZ|58399| Enterprise Bank &...|   11-Dec-09|     US|\n",
      "+--------------------+--------+---+-----+---------------------+------------+-------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Adicionar uma nova coluna\n",
    "df2 = df.withColumn('country', lit('US'))\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "899c18ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---+---------------------+------------+\n",
      "|           Bank Name|    City| ST|Acquiring Institution|Closing Date|\n",
      "+--------------------+--------+---+---------------------+------------+\n",
      "| First Bank of Idaho| Ketchum| ID|      U.S. Bank, N.A.|   24-Apr-09|\n",
      "|Amcore Bank, Nati...|Rockford| IL|          Harris N.A.|   23-Apr-10|\n",
      "|        Venture Bank|   Lacey| WA| First-Citizens Ba...|   11-Sep-09|\n",
      "|First State Bank ...|   Altus| OK|         Herring Bank|   31-Jul-09|\n",
      "|Valley Capital Ba...|    Mesa| AZ| Enterprise Bank &...|   11-Dec-09|\n",
      "+--------------------+--------+---+---------------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Apagar coluna \n",
    "df2 = df.drop('CERT')\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0af2a4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------------------+------------+\n",
      "|           Bank Name|    City|Acquiring Institution|Closing Date|\n",
      "+--------------------+--------+---------------------+------------+\n",
      "| First Bank of Idaho| Ketchum|      U.S. Bank, N.A.|   24-Apr-09|\n",
      "|Amcore Bank, Nati...|Rockford|          Harris N.A.|   23-Apr-10|\n",
      "|        Venture Bank|   Lacey| First-Citizens Ba...|   11-Sep-09|\n",
      "|First State Bank ...|   Altus|         Herring Bank|   31-Jul-09|\n",
      "|Valley Capital Ba...|    Mesa| Enterprise Bank &...|   11-Dec-09|\n",
      "+--------------------+--------+---------------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Apagar varias colunas \n",
    "df2 = df.drop(*[\"CERT\",\"ST\"])\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d372cdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------------------+------------+\n",
      "|           Bank Name|    City|Acquiring Institution|Closing Date|\n",
      "+--------------------+--------+---------------------+------------+\n",
      "| First Bank of Idaho| Ketchum|      U.S. Bank, N.A.|   24-Apr-09|\n",
      "|Amcore Bank, Nati...|Rockford|          Harris N.A.|   23-Apr-10|\n",
      "|        Venture Bank|   Lacey| First-Citizens Ba...|   11-Sep-09|\n",
      "|First State Bank ...|   Altus|         Herring Bank|   31-Jul-09|\n",
      "|Valley Capital Ba...|    Mesa| Enterprise Bank &...|   11-Dec-09|\n",
      "+--------------------+--------+---------------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Apagar varias colunas com reduce \n",
    "df2 = reduce(DataFrame.drop, [\"CERT\",\"ST\"], df)\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d76b8f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.count  : 561\n",
      "df2.count : 4\n",
      "df3.count : 9\n",
      "df4.count : 73\n"
     ]
    }
   ],
   "source": [
    "# Realizar filtros \n",
    "df2 = df.where(df['ST'] == 'NE')\n",
    "df3 = df.where(df['CERT'].between('1000','2000'))\n",
    "df4 = df.where(df['ST'].isin('NE','IL'))\n",
    "\n",
    "print('df.count  :', df.count())\n",
    "print('df2.count :', df2.count())\n",
    "print('df3.count :', df3.count())\n",
    "print('df4.count :', df4.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "340dce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+---+-----+---------------------+------------+\n",
      "|         Bank Name|   City| ST| CERT|Acquiring Institution|Closing Date|\n",
      "+------------------+-------+---+-----+---------------------+------------+\n",
      "|Ericson State Bank|Ericson| NE|18265| Farmers and Merch...|   14-Feb-20|\n",
      "+------------------+-------+---+-----+---------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Realizar filtros --> AND\n",
    "df2 = df.where((df['ST'] == 'NE') & (df['City'] == 'Ericson'))\n",
    "df2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba5eb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---+-----+---------------------+------------+\n",
      "|           Bank Name|    City| ST| CERT|Acquiring Institution|Closing Date|\n",
      "+--------------------+--------+---+-----+---------------------+------------+\n",
      "| First Bank of Idaho| Ketchum| ID|34396|      U.S. Bank, N.A.|   24-Apr-09|\n",
      "|Amcore Bank, Nati...|Rockford| IL| 3735|          Harris N.A.|   23-Apr-10|\n",
      "|        Venture Bank|   Lacey| WA|22868| First-Citizens Ba...|   11-Sep-09|\n",
      "|First State Bank ...|   Altus| OK| 9873|         Herring Bank|   31-Jul-09|\n",
      "|Valley Capital Ba...|    Mesa| AZ|58399| Enterprise Bank &...|   11-Dec-09|\n",
      "+--------------------+--------+---+-----+---------------------+------------+\n",
      "only showing top 5 rows\n",
      "Replace 7 in the above dataframe with 17 at all instances\n",
      "+--------------------+--------+---+-----+---------------------+------------+\n",
      "|           Bank Name|    City| ST| CERT|Acquiring Institution|Closing Date|\n",
      "+--------------------+--------+---+-----+---------------------+------------+\n",
      "| First Bank of Idaho| Ketchum| ID|34396|      U.S. Bank, N.A.|   24-Apr-09|\n",
      "|Amcore Bank, Nati...|Rockford| IL| 3735|          Harris N.A.|   23-Apr-10|\n",
      "|        Venture Bank|   Lacey| WA|22868| First-Citizens Ba...|   11-Sep-09|\n",
      "|First State Bank ...|   Altus| OK| 9873|         Herring Bank|   31-Jul-09|\n",
      "|Valley Capital Ba...|    Mesa| AZ|58399| Enterprise Bank &...|   11-Dec-09|\n",
      "+--------------------+--------+---+-----+---------------------+------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Alterar os dados --> Replace\n",
    "df.show(5)\n",
    "\n",
    "print('Replace 7 in the above dataframe with 17 at all instances')\n",
    "df.na.replace(7,17).show(5) # --> Dessa forma, substitui em todas as colunas o que for 7 por 17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74af7dfc",
   "metadata": {},
   "source": [
    "#### Aula 2 - Operações Básicas no Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17a17a",
   "metadata": {},
   "source": [
    "#### Aula 3 - Consultas e Seleções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8530260",
   "metadata": {},
   "source": [
    "#### Aula 4 - Operações entre Dataframes e Armazenamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b843ad",
   "metadata": {},
   "source": [
    "#### Aula 5 - Introdução aos Sistemas de Recomendação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093e302",
   "metadata": {},
   "source": [
    "#### Aula 6 - Recomendações com o Algoritmo ALS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambiente_fase3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
